{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a series of classes, these must be split equally into training validation and holdout datasets.\n",
    "\n",
    "now, in order to generate a series of minibatches, each of these must be randomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataSet(object):\n",
    "    \n",
    "    def __init__(self, filepath='../data/20news-18828', length=20000):\n",
    "        self.basepath = filepath\n",
    "        self.length=length\n",
    "        self.class_map={}\n",
    "        self.classes = os.listdir(filepath)\n",
    "        for index, value in enumerate(self.classes):\n",
    "            self.class_map[value] = index\n",
    "        self.dataset = None\n",
    "        \n",
    "    def load(self, class_map, dataset):\n",
    "        with open(class_map, 'r') as _file:\n",
    "            self.class_map = copy.copy(json.load(_file))\n",
    "        with open(dataset, 'r') as _file:\n",
    "            self.dataset = copy.copy(json.load(_file))\n",
    "        for cls in self.class_map:\n",
    "            random.shuffle(self.dataset[str(self.class_map[cls])])\n",
    "        \n",
    "    def create_datasets(self):\n",
    "\n",
    "        train = {}\n",
    "        val = {}\n",
    "        test ={}\n",
    "        \n",
    "        for i in self.classes:\n",
    "            train[self.class_map[i]]=[]\n",
    "            val[self.class_map[i]]=[]\n",
    "            test[self.class_map[i]]=[]\n",
    "            for filename in glob.glob(os.path.join(self.basepath, i, '*')):\n",
    "                r = np.random.random_sample()\n",
    "                if r > 0.95:\n",
    "                    test[self.class_map[i]].append(filename)\n",
    "                elif r > 0.9:\n",
    "                    val[self.class_map[i]].append(filename)\n",
    "                else:\n",
    "                    train[self.class_map[i]].append(filename)\n",
    "            random.shuffle(train[self.class_map[i]])\n",
    "            random.shuffle(test[self.class_map[i]])\n",
    "            random.shuffle(val[self.class_map[i]])\n",
    "            \n",
    "        with open('train.json', 'w') as output:\n",
    "            json.dump(train, output)\n",
    "        with open('test.json', 'w') as output:\n",
    "            json.dump(test, output)\n",
    "        with open('val.json', 'w') as output:\n",
    "            json.dump(val, output)                \n",
    "                \n",
    "        with open('class_map.json', 'w') as output:\n",
    "            json.dump(self.class_map, output)\n",
    "\n",
    "    def get_text(self, filename):\n",
    "        output= np.ndarray(shape=(self.length,), dtype=np.integer)\n",
    "        index = 0\n",
    "        with open(filename, 'r', encoding='utf-8', errors='ignore') as input_file:\n",
    "            for line in input_file.readlines():\n",
    "                for char in line:\n",
    "                    if index >= self.length:\n",
    "                        break\n",
    "                    output[index] = self.decode_character(char)\n",
    "                    index += 1\n",
    "        return output\n",
    "            \n",
    "    def decode_character(self, char):\n",
    "        try:\n",
    "            return ord(char)\n",
    "        except UnicodeDecodeError:\n",
    "            return 0\n",
    "    \n",
    "    def get_random_filenames(self):\n",
    "        tmp = []\n",
    "        for cls in  self.class_map:\n",
    "            try:\n",
    "                tmp.append( (self.dataset[str(self.class_map[cls])].pop(), self.class_map[cls]))\n",
    "            except IndexError:\n",
    "                raise StopIteration\n",
    "        random.shuffle(tmp)\n",
    "        return [i[0] for i in tmp], [i[1] for i in tmp]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "    \n",
    "    def next(self):\n",
    "        x, y = self.get_random_filenames()\n",
    "        tmp_x = []\n",
    "        for i in x:\n",
    "            encoding = self.get_text(i)\n",
    "            tmp_x.append(encoding)\n",
    "        x = tmp_x    \n",
    "        tmp_x = np.zeros(shape=(len(self.class_map), self.length))\n",
    "        for index, arr in enumerate(x):\n",
    "            tmp_x[index][:len(arr)] = arr\n",
    "        # So, now we're going to have to create the Y matrix\n",
    "        tmp_y = np.zeros(shape=(20,20))\n",
    "        for index, value in enumerate(y):\n",
    "                tmp_y[index, value] =1\n",
    "        return tmp_x, tmp_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextDataSet()\n",
    "dataset.create_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = TextDataSet()\n",
    "train_set.load('class_map.json', 'train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.516915798187256\n",
      "575\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "now = time.time()\n",
    "length=0\n",
    "for i in train_set:\n",
    "    length+=1\n",
    "print(time.time()-now)\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
